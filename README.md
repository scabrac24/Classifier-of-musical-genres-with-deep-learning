# Clasificador de GÃ©nero Musical con Deep Learning

Este proyecto permite clasificar gÃ©neros musicales a partir de clips de audio de 3 segundos en formato MP3. Utiliza un modelo de red neuronal profunda entrenado con caracterÃ­sticas extraÃ­das del audio mediante `librosa`, y ofrece una interfaz web construida con Flask para que cualquier usuario pueda cargar un archivo y obtener una predicciÃ³n. Para entrenar el modelo se uso el siguiente Dataset extraido de la plataforma Kaggle : https://www.kaggle.com/datasets/sivadithiyan/edm-music-genres , autoria de Sivadithiyan



## CaracterÃ­sticas

- Carga de archivos MP3 desde una interfaz web sencilla.
- Recorte automÃ¡tico de un fragmento de 3 segundos del archivo MP3 ingresado (este recorte se aplica a los 3 segundos siguientes despues de la espera que se puede modificar en el codigo), evitando silencios iniciales para mejorar la precisiÃ³n.
- ExtracciÃ³n de caracterÃ­sticas acÃºsticas con `librosa`.
- ClasificaciÃ³n del gÃ©nero con un modelo de aprendizaje profundo entrenado con TensorFlow/Keras.
- VisualizaciÃ³n de espectrogramas.
- Mostrar el gÃ©nero predicho junto con el nivel de confianza.
  
### Los generos que el modelo es capaz de reconocer son:

- Ambient ğŸŒŒ
- Big Room House ğŸ 
- Drum and Bass ğŸ¥
- Dubstep ğŸµ
- Future Garage/Wave Trap ğŸŒŠ
- Hardcore ğŸ”Š
- Hardstyle ğŸ’¥
- House ğŸ¡
- Lo-fi ğŸ¶
- Moombahton/Reggaeton ğŸµğŸŒ´
- Phonk ğŸ”¥
- Psytrance ğŸŒ€
- Synthwave ğŸ¹
- Techno ğŸ›ï¸
- Trance ğŸš€
- Trap â›“ï¸



## Requisitos

Asegurarse de tener Python 3.8 o superior.

Instalar las dependencias ejecutando:

pip install -r requirements.txt


---

# Detalles del Modelo

El modelo fue entrenado usando caracterÃ­sticas acÃºsticas extraÃ­das de clips de audio de 3 segundos. Las caracterÃ­sticas incluyen:

40 coeficientes MFCC

Chroma STFT

Tonnetz

Zero Crossing Rate

Spectral Centroid

Spectral Rolloff



## Red Neuronal utilizada:


- Capa densa de 128 unidades con ReLU, regularizaciÃ³n L2 y BatchNormalization

- Dropout de 0.4

- Capa densa de 64 unidades con ReLU, regularizaciÃ³n L2 y BatchNormalization

- Dropout de 0.3

- Capa densa de 32 unidades con ReLU

- Capa de salida Softmax para clasificaciÃ³n multiclase



## Entrenamiento:

- Optimizador: Adam con learning rate = 0.0005

- PÃ©rdida: Categorical Crossentropy

- MÃ©tricas: Accuracy, Precision, Recall

- Balanceo de clases con class_weight

- Early stopping con restauraciÃ³n de los mejores pesos

- ReducciÃ³n de tasa de aprendizaje despuÃ©s de 20 Ã©pocas



## EvaluaciÃ³n en conjunto de prueba:

Se imprimen Accuracy, Precision y Recall sobre los datos de prueba al correr model.py

---

# Funcionamiento de la AplicaciÃ³n Web

1) Acceder a la carpeta Model con cd .\Model\

2) Ejecutar python app.py en la terminal

3) Acceder a la interfaz web en http://127.0.0.1:5000

4) Cargar un archivo MP3 de duraciÃ³n mayor a 3 segundos.

5) El sistema recorta el audio evitando la espera ingresada en el codigo (para evitar silencios).

6) Se extraen caracterÃ­sticas y se normalizan usando el scaler.pkl entrenado.

7) El modelo predice el gÃ©nero y se genera un espectrograma del audio cargado.

8) El resultado mostrado incluye:

    -  GÃ©nero musical

    -  Confianza del modelo

    -  Imagen del espectrograma generado
